{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "> Real-world data rarely comes clean. Using Python and its libraries, you will gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. You will document your wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python (and its libraries) and/or SQL.\n",
    "\n",
    "> The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user [@dog_rates](https://twitter.com/dog_rates), also known as [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](https://knowyourmeme.com/memes/theyre-good-dogs-brent) WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "> WeRateDogs [downloaded their Twitter archive](https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive) and sent it to Udacity via email exclusively for you to use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. More on this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Steps Overview\n",
    "Your tasks in this project are as follows:\n",
    "\n",
    "- 1: Gathering data\n",
    "\n",
    "- 2: Assessing data\n",
    "\n",
    "- 3: Cleaning data\n",
    "\n",
    "- 4: Storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Gather Data:\n",
    "\n",
    ">Gathered all three pieces of data as described below in the wrangle_act.ipynb notebook.\n",
    ">  #### 1- The WeRateDogs Twitter archive:\n",
    "I Downloaded this file manually by clicking the following link: [twitter_archive_enhanced.csv.](https://support.twitter.com/articles/20170160) Once it is downloaded, I uploaded it and read the data into a pandas DataFrame.\n",
    "> #### 2- The tweet image predictions\n",
    "This file (image_predictions.tsv) is present in each tweet according to a neural network. It is hosted on Udacity's servers and I downloaded it programmatically using the Requests library and the following URL: [here](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "> #### 3- Data from the Twitter API\n",
    "I used [tweet_json.txt](https://video.udacity-data.com/topher/2018/November/5be5fb7d_tweet-json/tweet-json.txt) provided by udacity since Tweeter refuse my API access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Assessing Data\n",
    "> #### In this section I defined 2 issues:\n",
    ">\n",
    "> ### Quality issues\n",
    "\n",
    "> 1. 'None' assigned instead of 'NaN' for empty missing data {visual assessment}\n",
    "\n",
    "> 2. 'tweet_id' not a string. {programmatic assessment}\n",
    "\n",
    "> 3. 'source' column contains tag html. {visual assessment}\n",
    "\n",
    "> 4. timestamp not in type dtime {programmatic assessment}\n",
    "\n",
    "> 5.  column 'name' has values('a', 'Mo', 'Bo', 'O', 'Al', 'my', 'an', 'by', 'Ed', 'JD', 'Jo') {programmatic assessment}\n",
    "\n",
    "> 6. Rating dinominator has different values instead of 10 {programmatic assessment}+{visual assessment}\n",
    "\n",
    "> 7. expanded_urls has incorrect urls and duplicates such like:<br>(https://twitter.com/dog_rates/status/673320132811366400/photo/1,https://twitter.com/dog_rates/status/673320132811366400/photo/1,https://twitter.com/dog_rates/status/673320132811366400/photo/1,https://twitter.com/dog_rates/status/673320132811366400/photo/1 ) {programmatic assessment}\n",
    "\n",
    "> 8. Column names are incomprehensible to the reader such as ('P1', 'P2', 'P3') and contain strange Predictions(spatula, barrow, minibus,paper_towel,laptop ) {visual assessment}\n",
    "\n",
    "> 9. retweet_status has one value 'Original tweet' {visual assessment}\n",
    "\n",
    "> 10. columns no need {'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id',retweeted_status_timestamp', 'rating_denominator','img_num'}\n",
    "\n",
    "> 11. Column names are not clear to the user { 'source', 'text', 'name'}\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    ">1. Dataframes must be one df with No retweet ids  {visual assessment}\n",
    "\n",
    ">2. Dogtionary in 4 columns instead of one {visual assessment}\n",
    "\n",
    "> 3. expanded_urls and url have same values {visual assessment}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Cleaning Data\n",
    "- I Have made  a copy of the original data before cleaning.\n",
    "- I have used the Define-Code-Testframework.\n",
    "- I have documented Define-Code-Testframework.\n",
    "- I have documented each issue in a few Sentences.\n",
    "- I have successfully cleaned all issues identified in the assessing phase.\n",
    "- I have created a tidy master dataset with all pieces of gathered,cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Storing Data\n",
    ">In this section I store the cleaned master DataFrame in a CSV file with the main one named twitter_archive_master.csv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
